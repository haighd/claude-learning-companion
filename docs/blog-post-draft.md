# I Don't Write Code. I Built This Anyway.

A non-coder's honest story about building real software with AI.

**Jump to:**
[The Problem](#the-problem-i-wanted-to-solve) | [What It Looks Like](#what-directing-ai-actually-looks-like) | [Skills Needed](#what-skills-you-actually-need-that-arent-coding) | [Hard Parts](#the-hard-parts-honest) | [What I Built](#what-i-actually-shipped) | [GitHub](#what-i-actually-shipped)

---

I've never written a line of code. Not in a "I dabbled but gave up" way - I mean I genuinely don't know programming. I couldn't tell you the difference between Python and JavaScript syntax if you showed me both.

Last month, I shipped a working software system:
- SQLite database with 15+ tables
- FastAPI backend with WebSocket real-time streaming
- React dashboard with multiple views
- Automated test suite
- Cross-platform installers for Mac, Linux, and Windows

I didn't mass any tutorials. I didn't "learn to code first." I directed an AI to build it, piece by piece, over several weeks.

This is that story - honest, including the hard parts.

## The Problem I Wanted to Solve

I use Claude Code daily. It's powerful. But every session starts from zero.

You spend an hour debugging something, finally fix it, close the terminal... and next week Claude might make the exact same mistake. It has no memory of what happened. You end up re-explaining your project's quirks over and over.

I got frustrated. What if Claude could remember? Not through some AI magic - just structured notes that persist between sessions and get surfaced at the right time.

That's what I decided to build.

## What "Directing AI" Actually Looks Like

It's not "write me an app." That doesn't work for anything real.

It's more like being a product manager who can see the code being written in real-time and course-correct constantly.

A typical exchange:

> **Me:** "The dashboard should show heuristics with their confidence scores."
>
> **Claude:** *writes code, shows me the result*
>
> **Me:** "The confidence should be a progress bar, not just a number. And sort by highest confidence first."
>
> **Claude:** *updates code*
>
> **Me:** "That broke the other view. The heuristics tab is empty now."
>
> **Claude:** *debugs, finds the issue, fixes it*

Multiply that by hundreds of interactions over weeks. That's the process.

## What Skills You Actually Need (That Aren't Coding)

**Knowing what "done" looks like.** I couldn't write the code, but I knew when the dashboard looked right, when the data flow made sense, when something felt off.

**Product thinking.** Deciding what to build, what not to build, what order to build it in. The AI doesn't know your priorities.

**Persistence.** Things break constantly. Context gets lost. You have to keep steering back on track.

**Taste.** Knowing when something is over-engineered. Knowing when a solution is too clever. The AI will happily build complexity you don't need.

**Asking good questions.** "This feels slow" isn't useful. "The WebSocket reconnects every 2 seconds, is that normal?" gets you somewhere.

## The Hard Parts (Honest)

**Context limits are real.** Long sessions lose coherence. The AI forgets what it built two hours ago. I had to learn to work in focused chunks and re-establish context.

**Debugging is brutal.** When something breaks and you can't read the code, you're dependent on the AI to figure it out. Sometimes it goes in circles. Sometimes you have to start fresh.

**You can't verify independently.** A coder can read the solution and know if it's right. I have to trust the tests, trust the behavior, ask probing questions. It's uncomfortable.

**It's not faster than coding (probably).** A skilled developer would have built this quicker. But a skilled developer wasn't available. I was.

## The Meta Twist

Here's the thing: the system I built is designed to solve the exact problem I kept hitting while building it.

The framework gives Claude persistent memory - it records what worked, what failed, and surfaces that context before new tasks. I built it because I needed it while building it.

Every failure we hit got recorded. Every pattern that worked got captured. By the end, Claude was working better because it had all that history to draw from.

That's not AI getting smarter. That's *my* knowledge - the lessons from weeks of trial and error - being preserved and injected back into the AI's context.

## What I Actually Shipped

**Emergent Learning Framework** - persistent memory for Claude Code sessions.

- Records failures and successes automatically via hooks
- Tracks patterns ("heuristics") that gain confidence over time
- Dashboard to visualize what's been learned
- Query system to search past learnings
- Multi-agent coordination for complex tasks

It's open source. MIT license. You can install it and try it.

GitHub: [https://github.com/haighd/claude-learning-companion](https://github.com/haighd/claude-learning-companion)

## Who This Is For

If you're a non-coder wondering whether you can build real things with AI: yes, you can. But go in with realistic expectations.

You won't "vibe code" your way to a startup in a weekend. You will hit walls. You will get frustrated. You will ship something that feels held together with tape.

But you'll ship. And that's more than most people do.

The gap between "idea person" and "person who builds things" just got a lot smaller. Not gone - smaller.

I'm still not a coder. But I built something real. That's new.

---

*This post was written with help from Claude. The framework was built with Claude Code. I still can't read the code it wrote - but it works.*

